{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3292,"status":"ok","timestamp":1673122693403,"user":{"displayName":"NAVROOP SINGH","userId":"11640833057480195288"},"user_tz":-330},"id":"KMY3EihHcRw_","outputId":"6a5d830b-e3da-433c-dd82-920c05da2490"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3888,"status":"ok","timestamp":1673122697286,"user":{"displayName":"NAVROOP SINGH","userId":"11640833057480195288"},"user_tz":-330},"id":"oOc9SsTZcS-T","outputId":"e3280aa0-f374-4790-c911-52423407d27a"},"outputs":[],"source":["! pip install segmentation_models"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16,"status":"ok","timestamp":1673122697287,"user":{"displayName":"NAVROOP SINGH","userId":"11640833057480195288"},"user_tz":-330},"id":"q8vXKLH_cN1_","outputId":"25026ef0-4063-4e11-a36c-8bfca25c5e5b"},"outputs":[],"source":["import os\n","import tensorflow as tf\n","import numpy as np\n","from PIL import Image\n","from segmentation_models.losses import bce_jaccard_loss\n","from segmentation_models.metrics import iou_score  \n","from tensorflow.keras.preprocessing.image import load_img\n","from math import ceil\n","import threading\n","from time import sleep"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uxLVB-SKcN2C"},"outputs":[],"source":["custom_objects = {'binary_crossentropy_plus_jaccard_loss':bce_jaccard_loss, 'iou_score':iou_score}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CVPDVs3dcN2E"},"outputs":[],"source":["# Paths for input files and output\n","out_path = '/content/drive/MyDrive/CS507/unet/predictions/segmentation'\n","in_path = '/content/drive/MyDrive/CS507/unet/data/'\n","# classify_model_path = './content/drive/MyDrive/CS507/unet/CNN_classification_0.828.h5'\n","unet_model_path = '/content/drive/MyDrive/CS507/unet/resnet34_B8A_B11_B12_82.h5'\n","\n","# Bands used for prediction (must be in same order as in training)\n","# classify_bands = ['B3', 'B4', 'B8', 'B8A', 'B11', 'B12']\n","unet_bands = ['B8A', 'B11', 'B12']\n","\n","# Batch size for prediction (Must be multiple of 81 as each image split to 81 patches)\n","batch_size = 81*2"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VI-Owc9fceY5"},"outputs":[],"source":["if not os.path.exists(out_path):\n","    os.mkdir(out_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"boDwOYPccN2E"},"outputs":[],"source":["# def classify_predict(img_arr):\n","#     classify_prediction = classify_model.predict(img_arr)\n","#     return classify_prediction.argmax(axis=1).reshape(9,9)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pZ4YABU8cN2F"},"outputs":[],"source":["# classify_model = tf.keras.models.load_model(classify_model_path)\n","unet_model = tf.keras.models.load_model(unet_model_path, custom_objects, compile=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":237},"executionInfo":{"elapsed":9841,"status":"error","timestamp":1673121486207,"user":{"displayName":"NAVROOP SINGH","userId":"11640833057480195288"},"user_tz":-330},"id":"Mok1uUUAcN2G","outputId":"5613f873-919c-4b2c-969f-b4146fec33c7"},"outputs":[],"source":["# List of files as (scene_name, scene_num)\n","f_list = []\n","for file in os.listdir(in_path + 'atm_penetration/'):\n","    fsplit = file.split('_')\n","    scene_name = '_'.join(fsplit[:4])\n","    scene_num = int(fsplit[-1][:-4])\n","    f_list.append((scene_name, scene_num))\n","    \n","f_list.sort()\n","len(f_list)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PHtRrYSSeMzT"},"outputs":[],"source":["# Function to divide image to num*num patches\n","def crop_img(img, num, save_prefix='', ret_numpy=False):\n","    size = img.size\n","    crop_sizes = []\n","    for i in range(num):\n","        for j in range(num):\n","            x1 = i * size[0]//num\n","            x2 = x1 + size[0]//num\n","            y1 = j * size[1]//num\n","            y2 = y1 + size[1]//num\n","            crop_sizes.append((x1, y1, x2, y2))\n","\n","    imgs = []\n","    for i, s in enumerate(crop_sizes):\n","        cropped = img.crop(s)\n","        if ret_numpy:\n","            imgs.append( np.array(cropped))\n","        else:\n","            cropped.save(save_prefix + f'{i}.jpg', format='JPEG', quality=80)\n","    if ret_numpy:\n","        return np.stack(imgs, axis=0)\n","\n","# Return band image data of given scene name and number as a numpy array\n","def get_bands_arr(path, scene_name, scene_num, bands, crop_num, img_size):\n","    arr = []\n","    for b in bands:\n","        file_path = f'{path}{scene_name}_{b}_{scene_num}.jpg'\n","        img = Image.open(file_path).resize(img_size)\n","        arr.append(crop_img(img, crop_num, ret_numpy=True))\n","    return np.stack(arr, axis=3)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"t-Z01vjOcN2H"},"outputs":[],"source":["class Sequence_generator(tf.keras.utils.Sequence):\n","    \"\"\"Helper to iterate over the data (as Numpy arrays).\"\"\"\n","\n","    def __init__(self, f_list, bands, batch_size, img_size):\n","        self.batch_size = batch_size\n","        self.img_size = img_size\n","        self.f_list = f_list\n","        self.bands = bands\n","\n","    def __len__(self):\n","        return ceil(len(self.f_list) * 81 / self.batch_size)\n","\n","    def __getitem__(self, idx):\n","        \"\"\"Returns tuple (input, target) correspond to batch #idx.\"\"\"\n","        num = self.batch_size // 81\n","        i = idx * num\n","        batch_files = self.f_list[i : i + num]\n","        x = np.zeros((len(batch_files)*81,) + (self.img_size, self.img_size,)+\n","                     (len(self.bands),), dtype=\"float32\")\n","\n","        for j, file in enumerate(batch_files):\n","            scene_name, scene_num = file\n","            np_arr = get_bands_arr(\n","                in_path+'bands/' ,scene_name, scene_num, unet_bands, 9, (self.img_size*9, self.img_size*9))\n","            x[j*81:(j+1)*81] = np_arr\n","\n","        return x\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":554,"status":"ok","timestamp":1673121500436,"user":{"displayName":"NAVROOP SINGH","userId":"11640833057480195288"},"user_tz":-330},"id":"1KGXhFgggicR","outputId":"b98c7d97-c11c-4cd0-d231-2d52b81ca235"},"outputs":[],"source":["predict_gen = Sequence_generator(f_list[:5], unet_bands, batch_size, 256)\n","predict_gen[0].shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pjYPzy9Qjgti"},"outputs":[],"source":["# Save the results from unet predictions to PNG image\n","def save_files(files, unet_preds, c):\n","  for j in range(len(files)):\n","    out_image = Image.new('RGB', (2700, 2700), 'black')\n","    for k in range(81):\n","      paste_img(unet_preds[(j*81)+k], out_image, k, (300,300))\n","    scene_id, num = files[j]\n","    out_image.save(f'{out_path}/{scene_id}_{num}.png')\n","    c+=1\n","  print(f'\\nsaved: {c}')\n","\n","# Paste image patch (from numpy array) on output image at appropriate position\n","def paste_img(nparr, out_image, i, resize):\n","    other = nparr == 0\n","    burned = nparr == 1\n","    vegetation = nparr == 2\n","    unknown = nparr == 3\n","\n","    pred_arr = np.zeros(nparr.shape + (3,), dtype='uint8')\n","    pred_arr[vegetation] = [0, 255, 0]\n","    pred_arr[burned] = [255, 0, 0]\n","    pred_arr[unknown] = [255, 255, 255]\n","\n","    temp_img = Image.fromarray(pred_arr)\n","\n","    box = (i // 9 * 300, i % 9 * 300)\n","    out_image.paste(temp_img.resize(resize), box)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":69304,"status":"ok","timestamp":1673123037758,"user":{"displayName":"NAVROOP SINGH","userId":"11640833057480195288"},"user_tz":-330},"id":"1dtBAUoFcN2I","outputId":"1010af34-e2ee-4ab4-94b2-2f8940bfb3f7"},"outputs":[],"source":["div = 30\n","c = 0\n","threads = []\n","for i in range(ceil(len(f_list)/div)):\n","    # Divide f_list into batches of size 'div'\n","    print(f'batch: {i}')\n","    files = f_list[i*div: (i+1)*div]\n","\n","    # Unet prediction on files\n","    predict_gen = Sequence_generator(files, unet_bands, batch_size, 256)\n","    predictions = unet_model.predict(\n","        predict_gen,\n","        use_multiprocessing=True,\n","        workers=4,\n","        batch_size=batch_size\n","    )\n","    unet_preds = predictions.argmax(\n","        axis=3).astype('uint8')\n","\n","    # Thread to save predictions as images\n","    t = threading.Thread(target=save_files, args=(\n","        files[:], unet_preds.copy(), c))\n","    t.start()\n","    threads.append(t)\n","    c += div\n","\n","    # Limit maximum running threads to prevent RAM usage\n","    while True:\n","        active_threads = 0\n","        for t in threads:\n","            if t.is_alive():\n","                active_threads += 1\n","            else:\n","                threads.remove(t)\n","        if active_threads < 3:\n","            break\n","        else:\n","            sleep(1)\n","    # np.savez(f'./cropped/{i}.npz', unet_preds)/\n","\n","for t in threads:\n","    t.join()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10323,"status":"ok","timestamp":1673123114262,"user":{"displayName":"NAVROOP SINGH","userId":"11640833057480195288"},"user_tz":-330},"id":"1Hc97N4scwrf","outputId":"e2db7548-c603-4751-e703-2ccffad1782f"},"outputs":[],"source":["# Save outputs in nomalized form\n","from concurrent.futures import ThreadPoolExecutor\n","from tqdm import tqdm\n","files = os.listdir(out_path)\n","\n","err_files = []\n","\n","def normalize(file):\n","    in_file = out_path + '/' + file\n","    img = Image.open(in_file)\n","    mask = np.zeros(img.size)\n","    data = np.array(img)\n","\n","    try:\n","        red, green, blue = data.T\n","    except:\n","        err_files.append(file)\n","        return\n","\n","    mask[(red.T > 245) & (green.T < 10) & (blue.T < 10)] = 1     # red\n","    mask[(red.T < 10) & (green.T > 245) & (blue.T < 10)] = 2     # green\n","    mask[(red.T > 245) & (green.T > 245) & (blue.T > 245)] = 3   # white\n","    outimg = Image.fromarray(mask).convert('L')\n","    out_file = in_file.replace('segmentation', 'normalized')\n","    outimg.save(out_file)\n","\n","with ThreadPoolExecutor(max_workers=16) as executor:\n","    results = list(tqdm(executor.map(normalize, files), total=len(files)))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":409,"status":"ok","timestamp":1673123152632,"user":{"displayName":"NAVROOP SINGH","userId":"11640833057480195288"},"user_tz":-330},"id":"0xH5W2FM6R1r","outputId":"2c3e5003-0164-4417-d6f2-22acc8b9b0e8"},"outputs":[],"source":["err_files"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.6 (main, Nov 14 2022, 16:10:14) [GCC 11.3.0]"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"}}},"nbformat":4,"nbformat_minor":0}
